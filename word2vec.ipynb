{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ac2203",
   "metadata": {},
   "source": [
    "### Criação do corpus:\n",
    "---\n",
    "Corpus é colção de textos reunidos e organziados com criterios especificos para análise, servindo com base para estudos em linguistica computacional, PLN, dicionarios e IA\n",
    "\n",
    "Nesse exemplo de corpus, estou usando um texto retirado do artigo \"COMPUTING MACHINERY AND INTELLIGENCE\n",
    "By A. M. Turing\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19be2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i propose to consider the question, can machines think?', 'this should begin with definitions of the meaning of the terms machine and think.']\n"
     ]
    }
   ],
   "source": [
    "tiny_corpus = [\"I propose to consider the question, Can machines think?\", \n",
    "               \"This should begin with definitions of the meaning of the terms Machine and think.\"\n",
    "]\n",
    "tiny_corpus_lowered = [sentence.lower() for sentence in tiny_corpus]\n",
    "print(tiny_corpus_lowered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4f5165",
   "metadata": {},
   "source": [
    "### Tokenização\n",
    "---\n",
    "Processo de transformar um texto em unidades menores, chamadas de tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26ec19b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I propose to consider the question, Can machines think?', 'This should begin with definitions of the meaning of the terms Machine and think.']\n",
      "['i', 'propose', 'to', 'consider', 'the', 'question,', 'can', 'machines', 'think?', 'this', 'should', 'begin', 'with', 'definitions', 'of', 'the', 'meaning', 'of', 'the', 'terms', 'machine', 'and', 'think.']\n",
      "['propose', 'terms', 'machine', 'this', 'meaning', 'consider', 'think?', 'begin', 'to', 'the', 'think.', 'definitions', 'should', 'of', 'question,', 'i', 'can', 'and', 'machines', 'with']\n",
      "{0: 'propose', 1: 'terms', 2: 'machine', 3: 'this', 4: 'meaning', 5: 'consider', 6: 'think?', 7: 'begin', 8: 'to', 9: 'the', 10: 'think.', 11: 'definitions', 12: 'should', 13: 'of', 14: 'question,', 15: 'i', 16: 'can', 17: 'and', 18: 'machines', 19: 'with'}\n",
      "{'propose': 0, 'terms': 1, 'machine': 2, 'this': 3, 'meaning': 4, 'consider': 5, 'think?': 6, 'begin': 7, 'to': 8, 'the': 9, 'think.': 10, 'definitions': 11, 'should': 12, 'of': 13, 'question,': 14, 'i': 15, 'can': 16, 'and': 17, 'machines': 18, 'with': 19}\n"
     ]
    }
   ],
   "source": [
    "tiny_corpus_tokenized = [sentence.split() for sentence in tiny_corpus_lowered]\n",
    "print(tiny_corpus)\n",
    "\n",
    "words = [word for sentence in tiny_corpus_tokenized for word in sentence]\n",
    "print(words)\n",
    "\n",
    "unique_words = list(set(words))\n",
    "print(unique_words)\n",
    "\n",
    "id2word = {nr: word for nr, word in enumerate(unique_words)}\n",
    "print(id2word)\n",
    "\n",
    "word2id = {word: id for id, word in id2word.items()}\n",
    "print(word2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1900d6b4",
   "metadata": {},
   "source": [
    "### One-Hot Enconding:\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bbe7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'propose': [np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'terms': [np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'machine': [np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'this': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'meaning': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'consider': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'think?': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'begin': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'to': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'the': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'think.': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'definitions': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'should': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'of': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'question,': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'i': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'can': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0), np.float64(0.0)], 'and': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0), np.float64(0.0)], 'machines': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0), np.float64(0.0)], 'with': [np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(0.0), np.float64(1.0)]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "num_word = len(unique_words)\n",
    "word2one_hot = dict()\n",
    "\n",
    "for i in range(num_word):\n",
    "    zero_vec = np.zeros(num_word)\n",
    "    zero_vec[i] = 1\n",
    "    word2one_hot[id2word[i]] = list(zero_vec)\n",
    "\n",
    "print(word2one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6a387a",
   "metadata": {},
   "source": [
    "### SkipGram:\n",
    "---\n",
    "Modelo que indica o contexto de um documento a partir de uma palavra especifica que foi selecionada, usando as relações semanticas entre as palavras para parametro.\n",
    "\n",
    "De acordo com a ideia do Word2Vec, quanto mais vezes duas palavras aparecem no mesmo contexto, mais proximo serão seus singnicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152631d0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Word2Vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
